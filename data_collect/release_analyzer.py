import json
import time
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
import openai
import json_repair
from tqdm import tqdm

from .config import (
    OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_MODEL, ANALYSIS_CACHE_FILE,
    MAX_README_LENGTH, README_TRUNCATION_SUFFIX, PROMPTS
)

# --- Data Class Definitions ---

@dataclass
class FeatureAnalysis:
    """Represents a feature analysis result"""
    feature_type: str  # 'new_feature', 'improvement', 'bug_fix', 'other'
    description: str
    pr_links: List[str]  # Related PR links
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'FeatureAnalysis':
        return cls(**data)

@dataclass
class ReleaseAnalysis:
    """Represents a release analysis result"""
    tag_name: str
    repo_name: str
    new_features: List[FeatureAnalysis]
    improvements: List[FeatureAnalysis]
    bug_fixes: List[FeatureAnalysis]
    other_changes: List[FeatureAnalysis]
    processed_body: str  # Body with PR links processed
    analyzed_at: str
    
    def to_dict(self) -> Dict:
        return {
            'tag_name': self.tag_name,
            'repo_name': self.repo_name,
            'new_features': [f.to_dict() for f in self.new_features],
            'improvements': [f.to_dict() for f in self.improvements],
            'bug_fixes': [f.to_dict() for f in self.bug_fixes],
            'other_changes': [f.to_dict() for f in self.other_changes],
            'processed_body': self.processed_body,
            'analyzed_at': self.analyzed_at
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'ReleaseAnalysis':
        return cls(
            tag_name=data['tag_name'],
            repo_name=data['repo_name'],
            new_features=[FeatureAnalysis.from_dict(f) for f in data.get('new_features', [])],
            improvements=[FeatureAnalysis.from_dict(f) for f in data.get('improvements', [])],
            bug_fixes=[FeatureAnalysis.from_dict(f) for f in data.get('bug_fixes', [])],
            other_changes=[FeatureAnalysis.from_dict(f) for f in data.get('other_changes', [])],
            processed_body=data.get('processed_body', ''),
            analyzed_at=data.get('analyzed_at', '')
        )

# --- Cache Management ---

def load_analysis_cache() -> Dict[str, ReleaseAnalysis]:
    """Load analysis cache"""
    if ANALYSIS_CACHE_FILE.exists():
        try:
            with open(ANALYSIS_CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                cache = {}
                for key, analysis_data in data.items():
                    cache[key] = ReleaseAnalysis.from_dict(analysis_data)
                print(f"âœ… Loaded {len(cache)} release analysis results from cache")
                return cache
        except Exception as e:
            print(f"âš ï¸ Failed to load analysis cache: {e}")
            return {}
    return {}

def save_analysis_to_cache(analysis: ReleaseAnalysis):
    """Save analysis result to cache"""
    cache = {}
    if ANALYSIS_CACHE_FILE.exists():
        try:
            with open(ANALYSIS_CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
        except:
            pass
    
    cache_key = f"{analysis.repo_name}#{analysis.tag_name}"
    cache[cache_key] = analysis.to_dict()
    
    try:
        with open(ANALYSIS_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, indent=2, ensure_ascii=False)
        print(f"ðŸ’¾ Saved analysis result for {cache_key} to cache")
    except Exception as e:
        print(f"âš ï¸ Failed to save analysis cache: {e}")

# --- LLM Analysis ---

def analyze_release_with_llm(release_body: str, tag_name: str, repo_readme: str = "") -> Dict[str, List[Dict]]:
    """Use LLM to analyze feature changes and PR links in release body"""
    
    client = openai.OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    
    # Build prompt with README context
    readme_context = ""
    if repo_readme.strip():
        # Truncate README to avoid overly long prompt
        readme_excerpt = repo_readme[:MAX_README_LENGTH]
        if len(repo_readme) > MAX_README_LENGTH:
            readme_excerpt += README_TRUNCATION_SUFFIX
        readme_context = f"""Repository Context (README):
{readme_excerpt}

---
"""

    # Get prompts from config
    release_analysis_system_prompt = PROMPTS.release_analysis_system
    release_analysis_user_prompt_template = PROMPTS.release_analysis_user

    # Format the user prompt with variables
    prompt = release_analysis_user_prompt_template.format(
        readme_context=readme_context,
        tag_name=tag_name,
        release_body=release_body
    )

    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": release_analysis_system_prompt},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0
        )
        
        content = response.choices[0].message.content
        if content is None:
            print("âš ï¸ LLM returned empty content")
            return {"new_features": [], "improvements": [], "bug_fixes": [], "other_changes": []}
        result = json_repair.loads(content)
        return result
            
    except Exception as e:
        print(f"âš ï¸ LLM analysis failed: {e}")
        return {"new_features": [], "improvements": [], "bug_fixes": [], "other_changes": []}

# --- Main Function ---

def analyze_release(release, repo_name: str, repo_readme: str = "", use_cache: bool = True) -> Optional[ReleaseAnalysis]:
    """Analyze a single release"""
    cache_key = f"{repo_name}#{release.tag_name}"
    
    # Check cache
    if use_cache:
        cache = load_analysis_cache()
        if cache_key in cache:
            print(f"  > ðŸ”„ Loading analysis result for {release.tag_name} from cache")
            return cache[cache_key]
    
    print(f"  > ðŸ” Analyzing release for {release.tag_name}...")
    
    # LLM analysis, pass README content
    llm_result = analyze_release_with_llm(release.body, release.tag_name, repo_readme)
    
    # Convert to FeatureAnalysis objects
    def convert_to_feature_analysis(items: List[Dict], feature_type: str) -> List[FeatureAnalysis]:
        features = []
        for item in items:
            pr_links = []
            # Get PR IDs from LLM result and convert to full links
            if 'pr_ids' in item:
                for pr_id in item['pr_ids']:
                    pr_links.append(f"https://github.com/{repo_name}/pull/{pr_id}")
            
            features.append(FeatureAnalysis(
                feature_type=feature_type,
                description=item.get('description', ''),
                pr_links=pr_links
            ))
        return features
    
    analysis = ReleaseAnalysis(
        tag_name=release.tag_name,
        repo_name=repo_name,
        new_features=convert_to_feature_analysis(llm_result.get('new_features', []), 'new_feature'),
        improvements=convert_to_feature_analysis(llm_result.get('improvements', []), 'improvement'),
        bug_fixes=convert_to_feature_analysis(llm_result.get('bug_fixes', []), 'bug_fix'),
        other_changes=convert_to_feature_analysis(llm_result.get('other_changes', []), 'other'),
        processed_body=release.body,
        analyzed_at=time.strftime('%Y-%m-%d %H:%M:%S')
    )
    
    # Save to cache
    if use_cache:
        save_analysis_to_cache(analysis)
    
    return analysis

def analyze_repository_releases(repository) -> List[ReleaseAnalysis]:
    """Analyze all major releases of the repository"""
    print(f"--- Starting analysis of release features for repository {repository.full_name} ---")
    
    analyses = []
    
    # Use tqdm to show analysis progress
    with tqdm(repository.major_releases, desc=f"Analyzing {repository.full_name}", unit="release") as pbar:
        for release in pbar:
            pbar.set_description(f"Analyzing: {release.tag_name}")
            
            # Pass README content to analysis function
            analysis = analyze_release(release, repository.full_name, repository.readme_content)
            if analysis:
                analyses.append(analysis)
                # Show analysis result summary
                new_features_count = len(analysis.new_features)
                improvements_count = len(analysis.improvements)
                bug_fixes_count = len(analysis.bug_fixes)
                pbar.write(f"    âœ… {release.tag_name}: New features({new_features_count}) Improvements({improvements_count}) Fixes({bug_fixes_count})")
            
            # Avoid API rate limit
            time.sleep(1)
    
    return analyses